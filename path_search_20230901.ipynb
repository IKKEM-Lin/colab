{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnX8OzE33nmeboO+0y7DUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IKKEM-Lin/colab/blob/main/path_search_20230901.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 产物路径搜索，需上传[ttl文件](https://github.com/IKKEM-Lin/colab/blob/main/gen_turtle_20230901.ipynb)"
      ],
      "metadata": {
        "id": "fUenogiTchE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaEyaeYRcCHY"
      },
      "outputs": [],
      "source": [
        "# install dependencies\n",
        "! pip install pubchempy\n",
        "! pip install rdflib\n",
        "! pip install requests\n",
        "! pip install loguru\n",
        "! pip install networkx\n",
        "\n",
        "import pubchempy as pcp\n",
        "from rdflib import Namespace, Literal, URIRef, Graph as RDFGraph\n",
        "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
        "import networkx as nx\n",
        "from networkx import Graph as NXGraph\n",
        "import requests\n",
        "from loguru import logger\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import uuid\n",
        "import collections\n",
        "import hashlib\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rg = RDFGraph()\n",
        "rg.parse(\"./tripple.ttl\", format='turtle')\n",
        "\n",
        "G = rdflib_to_networkx_multidigraph(rg)\n",
        "print(\"networkx Graph loaded successfully with length {}\".format(len(G)))\n",
        "# Density\n",
        "print(\"DENSITY\")\n",
        "print(\"============\")\n",
        "print(\"The network density is {}\".format(nx.density(G)))"
      ],
      "metadata": {
        "id": "IdlaJakKdHru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = G.edges\n",
        "def find_edge(produce, property, edges = edges):\n",
        "  result = filter(lambda x: x[1] == produce and x[2] == property, edges)\n",
        "  return result\n",
        "\n",
        "def find_reactions_from_product(produce):\n",
        "  result = find_edge(produce, URIRef('react:has_product'))\n",
        "  return map(lambda x: x[0], result)\n",
        "\n",
        "def find_reactants_from_reaction(reaction):\n",
        "  result = find_edge(reaction, URIRef('spi:is_reactant_of'))\n",
        "  return map(lambda x: x[0], result)\n",
        "\n",
        "def get_products_from_reaction(reaction):\n",
        "  result = find_edge(reaction, URIRef('spi:is_product_of'))\n",
        "  return map(lambda x: x[0], result)\n",
        "\n",
        "def is_reaction(node):\n",
        "  result = filter(lambda x: x[0] == node and x[2] == URIRef('react:id'), edges)\n",
        "  return True if list(result) else False\n",
        "\n",
        "def search_one(name, max_steps=3):\n",
        "  def get_spieces(name):\n",
        "    # 拿到name对应的ID\n",
        "    id_str, URI = get_spieces_class_operations(name, {})\n",
        "    if \"CHEBI\" in id_str:\n",
        "      return URIRef(\"obo:{}\".format(id_str))\n",
        "    else:\n",
        "      return URIRef(\"spi:{}\".format(id_str))\n",
        "  query_str = get_spieces(name)\n",
        "  duplicated_reactions = list(find_reactions_from_product(query_str));\n",
        "  res_path = list(map(lambda x: [query_str, x], find_reactions_from_product(query_str)))\n",
        "  logger.info(query_str) #################\n",
        "  result_hash = \"\"\n",
        "  condition = lambda path: len(path) < max_steps*2\n",
        "  while any(map(condition ,res_path)):\n",
        "    new_res_paths = []\n",
        "    wait_process_paths = []\n",
        "    for path in res_path:\n",
        "      if condition(path):\n",
        "        wait_process_paths.append(path)\n",
        "      else:\n",
        "        new_res_paths.append(path)\n",
        "    for path in wait_process_paths:\n",
        "      # print(path, is_reaction(path[-1])) #################\n",
        "      if is_reaction(path[-1]):\n",
        "        temp_reactants = list(find_reactants_from_reaction(path[-1]))\n",
        "        substant_in_previous = any([item in path for item in temp_reactants])\n",
        "        if substant_in_previous:\n",
        "          # end with reaction, need to cut off finally\n",
        "          new_res_paths.append(path)\n",
        "        else:\n",
        "          new_res_paths.extend([path[:] + ([reactant]) for reactant in temp_reactants])\n",
        "      else:\n",
        "        temp_reactions = list(find_reactions_from_product(path[-1]))\n",
        "        temp_wait_process_reactions = [reaction for reaction in temp_reactions if (reaction not in path and reaction not in duplicated_reactions)]\n",
        "        # print(\"temp_reactions\", temp_reactions, path[-1]) #################\n",
        "        if not temp_wait_process_reactions:\n",
        "          new_res_paths.append(path)\n",
        "          continue\n",
        "        new_res_paths.extend([path[:] + ([reaction]) for reaction in temp_wait_process_reactions])\n",
        "        duplicated_reactions.extend(temp_wait_process_reactions)\n",
        "    res_path = new_res_paths[:]\n",
        "    new_hash = hash(str(res_path))\n",
        "    # print(res_path, new_hash) #################\n",
        "    if new_hash == result_hash:\n",
        "      break\n",
        "    else:\n",
        "      result_hash = new_hash\n",
        "  return res_path"
      ],
      "metadata": {
        "id": "w5_mS1TSdO0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = search_one(\"carbon dioxide\")\n",
        "\n",
        "print(\"----------------- Result ------------------------\")\n",
        "for path in paths:\n",
        "  print(path)"
      ],
      "metadata": {
        "id": "xhil1P6odRdk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}